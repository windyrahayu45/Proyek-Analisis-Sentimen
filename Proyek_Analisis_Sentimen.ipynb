{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeMBD7bwHj5R04QJI0bHyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windyrahayu45/Proyek-Analisis-Sentimen/blob/main/Proyek_Analisis_Sentimen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import library"
      ],
      "metadata": {
        "id": "41y87sgNdxBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDENqeC-dkFv",
        "outputId": "cfb9a1b0-6c57-4a60-9071-58c05d33a3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Pastikan stopwords bahasa Indonesia tersedia\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"indonesian\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Shop ID dan Item ID dari URL produk Shopee Skin 1004\n",
        "SHOP_ID = 555954448\n",
        "ITEM_ID = 20748780200\n",
        "MAX_REVIEWS = 3000\n",
        "LIMIT = 50\n",
        "\n",
        "# Set Header & Cookies dari Browser\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Referer\": f\"https://shopee.co.id/product/{SHOP_ID}/{ITEM_ID}/\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Fungsi scraping dengan session\n",
        "def scrape_shopee_reviews(shop_id, item_id, max_reviews=3000):\n",
        "    session = requests.Session()\n",
        "    session.headers.update(HEADERS)\n",
        "\n",
        "    reviews = []\n",
        "    offset = 0\n",
        "\n",
        "    while len(reviews) < max_reviews:\n",
        "        print(f\"ðŸ”„ Mengambil data dari offset {offset}...\")\n",
        "        url = f\"https://shopee.co.id/api/v2/item/get_ratings?itemid={item_id}&shopid={shop_id}&offset={offset}&limit={LIMIT}&type=0\"\n",
        "\n",
        "        try:\n",
        "            response = session.get(url)\n",
        "            if response.status_code != 200:\n",
        "                print(\"âš ï¸ Gagal mengambil data, status code:\", response.status_code)\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            if \"data\" in data and \"ratings\" in data[\"data\"]:\n",
        "                for review in data[\"data\"][\"ratings\"]:\n",
        "                    reviews.append({\n",
        "                        \"Username\": review.get(\"author_username\", \"\"),\n",
        "                        \"Rating\": review.get(\"rating_star\", 0),\n",
        "                        \"Komentar\": review.get(\"comment\", \"\")\n",
        "                    })\n",
        "\n",
        "            offset += LIMIT\n",
        "            if len(data[\"data\"][\"ratings\"]) < LIMIT:\n",
        "                break\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Terjadi kesalahan:\", str(e))\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(reviews)\n",
        "\n",
        "# Jalankan scraping\n",
        "df_reviews = scrape_shopee_reviews(SHOP_ID, ITEM_ID, MAX_REVIEWS)\n",
        "\n",
        "# Simpan hasil scraping ke file CSV\n",
        "df_reviews.to_csv(\"shopee_reviews_fixed.csv\", index=False)\n",
        "print(\"âœ… Scraping selesai! Data disimpan sebagai 'shopee_reviews_fixed.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-qafHihd9yL",
        "outputId": "6befd8fe-a4ad-48db-c823-f4085c8d9340"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Mengambil data dari offset 0...\n",
            "ðŸ”„ Mengambil data dari offset 50...\n",
            "ðŸ”„ Mengambil data dari offset 100...\n",
            "ðŸ”„ Mengambil data dari offset 150...\n",
            "ðŸ”„ Mengambil data dari offset 200...\n",
            "ðŸ”„ Mengambil data dari offset 250...\n",
            "ðŸ”„ Mengambil data dari offset 300...\n",
            "ðŸ”„ Mengambil data dari offset 350...\n",
            "ðŸ”„ Mengambil data dari offset 400...\n",
            "ðŸ”„ Mengambil data dari offset 450...\n",
            "ðŸ”„ Mengambil data dari offset 500...\n",
            "ðŸ”„ Mengambil data dari offset 550...\n",
            "ðŸ”„ Mengambil data dari offset 600...\n",
            "ðŸ”„ Mengambil data dari offset 650...\n",
            "ðŸ”„ Mengambil data dari offset 700...\n",
            "ðŸ”„ Mengambil data dari offset 750...\n",
            "ðŸ”„ Mengambil data dari offset 800...\n",
            "ðŸ”„ Mengambil data dari offset 850...\n",
            "ðŸ”„ Mengambil data dari offset 900...\n",
            "ðŸ”„ Mengambil data dari offset 950...\n",
            "ðŸ”„ Mengambil data dari offset 1000...\n",
            "ðŸ”„ Mengambil data dari offset 1050...\n",
            "ðŸ”„ Mengambil data dari offset 1100...\n",
            "ðŸ”„ Mengambil data dari offset 1150...\n",
            "ðŸ”„ Mengambil data dari offset 1200...\n",
            "ðŸ”„ Mengambil data dari offset 1250...\n",
            "ðŸ”„ Mengambil data dari offset 1300...\n",
            "ðŸ”„ Mengambil data dari offset 1350...\n",
            "ðŸ”„ Mengambil data dari offset 1400...\n",
            "ðŸ”„ Mengambil data dari offset 1450...\n",
            "ðŸ”„ Mengambil data dari offset 1500...\n",
            "ðŸ”„ Mengambil data dari offset 1550...\n",
            "ðŸ”„ Mengambil data dari offset 1600...\n",
            "ðŸ”„ Mengambil data dari offset 1650...\n",
            "ðŸ”„ Mengambil data dari offset 1700...\n",
            "ðŸ”„ Mengambil data dari offset 1750...\n",
            "ðŸ”„ Mengambil data dari offset 1800...\n",
            "ðŸ”„ Mengambil data dari offset 1850...\n",
            "ðŸ”„ Mengambil data dari offset 1900...\n",
            "ðŸ”„ Mengambil data dari offset 1950...\n",
            "ðŸ”„ Mengambil data dari offset 2000...\n",
            "ðŸ”„ Mengambil data dari offset 2050...\n",
            "ðŸ”„ Mengambil data dari offset 2100...\n",
            "ðŸ”„ Mengambil data dari offset 2150...\n",
            "ðŸ”„ Mengambil data dari offset 2200...\n",
            "ðŸ”„ Mengambil data dari offset 2250...\n",
            "ðŸ”„ Mengambil data dari offset 2300...\n",
            "ðŸ”„ Mengambil data dari offset 2350...\n",
            "ðŸ”„ Mengambil data dari offset 2400...\n",
            "ðŸ”„ Mengambil data dari offset 2450...\n",
            "ðŸ”„ Mengambil data dari offset 2500...\n",
            "ðŸ”„ Mengambil data dari offset 2550...\n",
            "ðŸ”„ Mengambil data dari offset 2600...\n",
            "ðŸ”„ Mengambil data dari offset 2650...\n",
            "ðŸ”„ Mengambil data dari offset 2700...\n",
            "ðŸ”„ Mengambil data dari offset 2750...\n",
            "ðŸ”„ Mengambil data dari offset 2800...\n",
            "ðŸ”„ Mengambil data dari offset 2850...\n",
            "ðŸ”„ Mengambil data dari offset 2900...\n",
            "ðŸ”„ Mengambil data dari offset 2950...\n",
            "âœ… Scraping selesai! Data disimpan sebagai 'shopee_reviews_fixed.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset hasil scraping\n",
        "df = pd.read_csv(\"shopee_reviews_fixed.csv\")\n",
        "\n",
        "# Fungsi membersihkan teks ulasan\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"\\d+\", \"\", text)\n",
        "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "        text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "df[\"Komentar_Bersih\"] = df[\"Komentar\"].apply(clean_text)\n",
        "\n",
        "# Label sentimen berdasarkan rating\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return \"Positif\"\n",
        "    elif rating == 3:\n",
        "        return \"Netral\"\n",
        "    else:\n",
        "        return \"Negatif\"\n",
        "\n",
        "df[\"Sentimen\"] = df[\"Rating\"].apply(label_sentiment)\n",
        "\n",
        "# Simpan hasil preprocessing\n",
        "df.to_csv(\"shopee_reviews_labeled.csv\", index=False)\n",
        "print(\"âœ… Data berhasil diproses! Disimpan sebagai 'shopee_reviews_labeled.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn1psLgagHE7",
        "outputId": "80608ff9-618e-485c-acf1-96b61df44f5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data berhasil diproses! Disimpan sebagai 'shopee_reviews_labeled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df[\"Komentar_Bersih\"]).toarray()\n",
        "y = df[\"Sentimen\"].map({\"Positif\": 1, \"Netral\": 0, \"Negatif\": -1})\n",
        "\n",
        "# Split data menjadi training & testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "NDGVIpkjgWAy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Model SVM\n",
        "svm_model = SVC(kernel=\"linear\")\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Model Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "QFADYwC6gZcg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_name, y_true, y_pred):\n",
        "    print(f\"\\nðŸ“Š Evaluasi Model: {model_name}\")\n",
        "    print(f\"Akurasi: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Evaluasi masing-masing model\n",
        "evaluate_model(\"Naive Bayes\", y_test, nb_pred)\n",
        "evaluate_model(\"SVM\", y_test, svm_pred)\n",
        "evaluate_model(\"Random Forest\", y_test, rf_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3pttnyWgc1o",
        "outputId": "f846e4c5-b8e5-49ca-e6ca-eda0fbaf3bf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Evaluasi Model: Naive Bayes\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n",
            "\n",
            "ðŸ“Š Evaluasi Model: SVM\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n",
            "\n",
            "ðŸ“Š Evaluasi Model: Random Forest\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}