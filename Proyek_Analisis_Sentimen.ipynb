{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeMBD7bwHj5R04QJI0bHyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/windyrahayu45/Proyek-Analisis-Sentimen/blob/main/Proyek_Analisis_Sentimen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import library"
      ],
      "metadata": {
        "id": "41y87sgNdxBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDENqeC-dkFv",
        "outputId": "cfb9a1b0-6c57-4a60-9071-58c05d33a3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Pastikan stopwords bahasa Indonesia tersedia\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"indonesian\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Shop ID dan Item ID dari URL produk Shopee Skin 1004\n",
        "SHOP_ID = 555954448\n",
        "ITEM_ID = 20748780200\n",
        "MAX_REVIEWS = 3000\n",
        "LIMIT = 50\n",
        "\n",
        "# Set Header & Cookies dari Browser\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
        "    \"Referer\": f\"https://shopee.co.id/product/{SHOP_ID}/{ITEM_ID}/\",\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Fungsi scraping dengan session\n",
        "def scrape_shopee_reviews(shop_id, item_id, max_reviews=3000):\n",
        "    session = requests.Session()\n",
        "    session.headers.update(HEADERS)\n",
        "\n",
        "    reviews = []\n",
        "    offset = 0\n",
        "\n",
        "    while len(reviews) < max_reviews:\n",
        "        print(f\"🔄 Mengambil data dari offset {offset}...\")\n",
        "        url = f\"https://shopee.co.id/api/v2/item/get_ratings?itemid={item_id}&shopid={shop_id}&offset={offset}&limit={LIMIT}&type=0\"\n",
        "\n",
        "        try:\n",
        "            response = session.get(url)\n",
        "            if response.status_code != 200:\n",
        "                print(\"⚠️ Gagal mengambil data, status code:\", response.status_code)\n",
        "                break\n",
        "\n",
        "            data = response.json()\n",
        "            if \"data\" in data and \"ratings\" in data[\"data\"]:\n",
        "                for review in data[\"data\"][\"ratings\"]:\n",
        "                    reviews.append({\n",
        "                        \"Username\": review.get(\"author_username\", \"\"),\n",
        "                        \"Rating\": review.get(\"rating_star\", 0),\n",
        "                        \"Komentar\": review.get(\"comment\", \"\")\n",
        "                    })\n",
        "\n",
        "            offset += LIMIT\n",
        "            if len(data[\"data\"][\"ratings\"]) < LIMIT:\n",
        "                break\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Terjadi kesalahan:\", str(e))\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(reviews)\n",
        "\n",
        "# Jalankan scraping\n",
        "df_reviews = scrape_shopee_reviews(SHOP_ID, ITEM_ID, MAX_REVIEWS)\n",
        "\n",
        "# Simpan hasil scraping ke file CSV\n",
        "df_reviews.to_csv(\"shopee_reviews_fixed.csv\", index=False)\n",
        "print(\"✅ Scraping selesai! Data disimpan sebagai 'shopee_reviews_fixed.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-qafHihd9yL",
        "outputId": "6befd8fe-a4ad-48db-c823-f4085c8d9340"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Mengambil data dari offset 0...\n",
            "🔄 Mengambil data dari offset 50...\n",
            "🔄 Mengambil data dari offset 100...\n",
            "🔄 Mengambil data dari offset 150...\n",
            "🔄 Mengambil data dari offset 200...\n",
            "🔄 Mengambil data dari offset 250...\n",
            "🔄 Mengambil data dari offset 300...\n",
            "🔄 Mengambil data dari offset 350...\n",
            "🔄 Mengambil data dari offset 400...\n",
            "🔄 Mengambil data dari offset 450...\n",
            "🔄 Mengambil data dari offset 500...\n",
            "🔄 Mengambil data dari offset 550...\n",
            "🔄 Mengambil data dari offset 600...\n",
            "🔄 Mengambil data dari offset 650...\n",
            "🔄 Mengambil data dari offset 700...\n",
            "🔄 Mengambil data dari offset 750...\n",
            "🔄 Mengambil data dari offset 800...\n",
            "🔄 Mengambil data dari offset 850...\n",
            "🔄 Mengambil data dari offset 900...\n",
            "🔄 Mengambil data dari offset 950...\n",
            "🔄 Mengambil data dari offset 1000...\n",
            "🔄 Mengambil data dari offset 1050...\n",
            "🔄 Mengambil data dari offset 1100...\n",
            "🔄 Mengambil data dari offset 1150...\n",
            "🔄 Mengambil data dari offset 1200...\n",
            "🔄 Mengambil data dari offset 1250...\n",
            "🔄 Mengambil data dari offset 1300...\n",
            "🔄 Mengambil data dari offset 1350...\n",
            "🔄 Mengambil data dari offset 1400...\n",
            "🔄 Mengambil data dari offset 1450...\n",
            "🔄 Mengambil data dari offset 1500...\n",
            "🔄 Mengambil data dari offset 1550...\n",
            "🔄 Mengambil data dari offset 1600...\n",
            "🔄 Mengambil data dari offset 1650...\n",
            "🔄 Mengambil data dari offset 1700...\n",
            "🔄 Mengambil data dari offset 1750...\n",
            "🔄 Mengambil data dari offset 1800...\n",
            "🔄 Mengambil data dari offset 1850...\n",
            "🔄 Mengambil data dari offset 1900...\n",
            "🔄 Mengambil data dari offset 1950...\n",
            "🔄 Mengambil data dari offset 2000...\n",
            "🔄 Mengambil data dari offset 2050...\n",
            "🔄 Mengambil data dari offset 2100...\n",
            "🔄 Mengambil data dari offset 2150...\n",
            "🔄 Mengambil data dari offset 2200...\n",
            "🔄 Mengambil data dari offset 2250...\n",
            "🔄 Mengambil data dari offset 2300...\n",
            "🔄 Mengambil data dari offset 2350...\n",
            "🔄 Mengambil data dari offset 2400...\n",
            "🔄 Mengambil data dari offset 2450...\n",
            "🔄 Mengambil data dari offset 2500...\n",
            "🔄 Mengambil data dari offset 2550...\n",
            "🔄 Mengambil data dari offset 2600...\n",
            "🔄 Mengambil data dari offset 2650...\n",
            "🔄 Mengambil data dari offset 2700...\n",
            "🔄 Mengambil data dari offset 2750...\n",
            "🔄 Mengambil data dari offset 2800...\n",
            "🔄 Mengambil data dari offset 2850...\n",
            "🔄 Mengambil data dari offset 2900...\n",
            "🔄 Mengambil data dari offset 2950...\n",
            "✅ Scraping selesai! Data disimpan sebagai 'shopee_reviews_fixed.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset hasil scraping\n",
        "df = pd.read_csv(\"shopee_reviews_fixed.csv\")\n",
        "\n",
        "# Fungsi membersihkan teks ulasan\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"\\d+\", \"\", text)\n",
        "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "        text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "df[\"Komentar_Bersih\"] = df[\"Komentar\"].apply(clean_text)\n",
        "\n",
        "# Label sentimen berdasarkan rating\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return \"Positif\"\n",
        "    elif rating == 3:\n",
        "        return \"Netral\"\n",
        "    else:\n",
        "        return \"Negatif\"\n",
        "\n",
        "df[\"Sentimen\"] = df[\"Rating\"].apply(label_sentiment)\n",
        "\n",
        "# Simpan hasil preprocessing\n",
        "df.to_csv(\"shopee_reviews_labeled.csv\", index=False)\n",
        "print(\"✅ Data berhasil diproses! Disimpan sebagai 'shopee_reviews_labeled.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn1psLgagHE7",
        "outputId": "80608ff9-618e-485c-acf1-96b61df44f5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data berhasil diproses! Disimpan sebagai 'shopee_reviews_labeled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df[\"Komentar_Bersih\"]).toarray()\n",
        "y = df[\"Sentimen\"].map({\"Positif\": 1, \"Netral\": 0, \"Negatif\": -1})\n",
        "\n",
        "# Split data menjadi training & testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "NDGVIpkjgWAy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Model SVM\n",
        "svm_model = SVC(kernel=\"linear\")\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Model Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "QFADYwC6gZcg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_name, y_true, y_pred):\n",
        "    print(f\"\\n📊 Evaluasi Model: {model_name}\")\n",
        "    print(f\"Akurasi: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Evaluasi masing-masing model\n",
        "evaluate_model(\"Naive Bayes\", y_test, nb_pred)\n",
        "evaluate_model(\"SVM\", y_test, svm_pred)\n",
        "evaluate_model(\"Random Forest\", y_test, rf_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3pttnyWgc1o",
        "outputId": "f846e4c5-b8e5-49ca-e6ca-eda0fbaf3bf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Evaluasi Model: Naive Bayes\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n",
            "\n",
            "📊 Evaluasi Model: SVM\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n",
            "\n",
            "📊 Evaluasi Model: Random Forest\n",
            "Akurasi: 0.9950\n",
            "Confusion Matrix:\n",
            "[[  0   0   1]\n",
            " [  0   0   2]\n",
            " [  0   0 597]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         1\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.99      1.00      1.00       597\n",
            "\n",
            "    accuracy                           0.99       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.99      0.99      0.99       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}